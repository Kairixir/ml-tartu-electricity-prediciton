{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMfr-moDJcJB",
    "tags": []
   },
   "source": [
    "# Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Colab setup\n",
    "---------- Start of generic setup code to get kaggle credentials login and data to work with. Copied much from Workshop 2 ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to read csv file into Colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "!pip install -U -q scikeras\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KCwkJq2oGfV_"
   },
   "outputs": [],
   "source": [
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-Cy22BWHcoX"
   },
   "source": [
    "https://drive.google.com/file/d/1DeYgEzZ8Bs8Y3QsHd5YsV-3D-SzVAm4x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "X36gG7t3GjSV"
   },
   "outputs": [],
   "source": [
    "# GET data from file I've uploaded to my drive. Use your own kaggle.json and google auth logins etc\n",
    "downloaded = drive.CreateFile({\"id\": \"1DeYgEzZ8Bs8Y3QsHd5YsV-3D-SzVAm4x\"})\n",
    "downloaded.GetContentFile(\"predict-energy-consumption.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zeCWSQdyHe7k",
    "outputId": "d71f97c7-530e-4238-e700-f61dbfe4d220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  predict-energy-consumption.zip\n",
      "  inflating: sample_submission.csv   \n",
      "  inflating: test.csv                \n",
      "  inflating: train.csv               \n",
      "predict-energy-consumption.zip\tsample_submission.csv  train.csv\n",
      "sample_data\t\t\ttest.csv\n"
     ]
    }
   ],
   "source": [
    "!unzip predict-energy-consumption.zip\n",
    "\n",
    "!ls\n",
    "!mkdir data\n",
    "!mv *.csv data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "3HjDS_qKGMj9",
    "outputId": "34b48718-9122-4d4a-cad7-c84c8d21e69e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-c23b2600-aaf0-489d-96d5-d9a0b5c630a1\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-c23b2600-aaf0-489d-96d5-d9a0b5c630a1\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.upload()\n",
    "# upload your kaggle.json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biC_tjjqDgkm"
   },
   "source": [
    "Processing data from the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6epI7FjF5As",
    "outputId": "39b03a5f-7a0a-4c44-dc84-42226d596e83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- path is now set to: {/content}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "!mkdir /root/.kaggle/\n",
    "!mv kaggle.json /root/.kaggle/kaggle.json\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle config set -n path -v{/content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JC4j4M33DcAy"
   },
   "outputs": [],
   "source": [
    "# GENERIC SUBMIT FUNCTION (uncomment when you want to submit)\n",
    "\n",
    "# submission = pd.DataFrame(\n",
    "#    {'key': test.key, 'fare_amount': val_predictions},\n",
    "#    columns = ['key', 'fare_amount'])\n",
    "# submission.to_csv('submission.csv', index = False)\n",
    "\n",
    "\n",
    "#!kaggle competitions submit -c predict-electricity-consumption -f submission.csv -m \"[TEAM NAME] Submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Libraries setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-10T17:41:00.208117Z",
     "iopub.status.busy": "2022-11-10T17:41:00.207219Z",
     "iopub.status.idle": "2022-11-10T17:41:04.294960Z",
     "shell.execute_reply": "2022-11-10T17:41:04.293645Z",
     "shell.execute_reply.started": "2022-11-10T17:41:00.207970Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modification functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-10T17:41:11.325933Z",
     "iopub.status.busy": "2022-11-10T17:41:11.324585Z",
     "iopub.status.idle": "2022-11-10T17:41:11.360690Z",
     "shell.execute_reply": "2022-11-10T17:41:11.359020Z",
     "shell.execute_reply.started": "2022-11-10T17:41:11.325874Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replaceNanWithZero(test, train, labels):\n",
    "    train_labels = labels.replace(np.nan, 0.0)\n",
    "\n",
    "    for col in train.columns:\n",
    "        train[col] = train[col].replace(np.nan, 0.0)\n",
    "\n",
    "    for col in test.columns:\n",
    "        test[col] = test[col].replace(np.nan, 0.0)\n",
    "\n",
    "    return test, train, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-10T17:41:11.369028Z",
     "iopub.status.busy": "2022-11-10T17:41:11.366561Z",
     "iopub.status.idle": "2022-11-10T17:41:12.333350Z",
     "shell.execute_reply": "2022-11-10T17:41:12.328804Z",
     "shell.execute_reply.started": "2022-11-10T17:41:11.368960Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PCA to get a lesser number of features, then going to feed into basic nn see what we can do\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def PCA_Performance(train, test):\n",
    "    variance = [0.5, 0.6, 0.75, 0.8, 0.85, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99]\n",
    "\n",
    "    for var in variance:\n",
    "        pca = PCA(n_components=var)\n",
    "        pca.fit(train)\n",
    "        transformed_Train = pca.transform(train)\n",
    "        # transformed_Test = pca.transform(test)\n",
    "        print(\n",
    "            f\"Retained {var} of variance with {len(transformed_Train.T)} number of features\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-10T17:41:12.336358Z",
     "iopub.status.busy": "2022-11-10T17:41:12.335707Z",
     "iopub.status.idle": "2022-11-10T17:41:12.599019Z",
     "shell.execute_reply": "2022-11-10T17:41:12.594054Z",
     "shell.execute_reply.started": "2022-11-10T17:41:12.336317Z"
    },
    "id": "TNkzNqt7IhVz",
    "outputId": "cfe12431-9d30-46f1-9425-7da3aa60f276",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qn/lk9fg3fs0hg9v8b7zh5lbybw0000gn/T/ipykernel_60775/1851060134.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  train = train.drop([\"consumption\"], 1)\n"
     ]
    }
   ],
   "source": [
    "# Here we can split into train/test for verification while we train whatever works)\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "train_labels = train[\"consumption\"]  # y vals in this case are concumption\n",
    "\n",
    "# GIVEN time is a string we just gonna drop that mfer, cbf processing it etc\n",
    "train = train.drop([\"time\"], axis=1)\n",
    "train = train.drop([\"consumption\"], 1)\n",
    "# print(train)\n",
    "\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "test = test.drop([\"time\"], axis=1)\n",
    "# Have to predict consumption for these values. Consumption unkown.\n",
    "\n",
    "# print(train)\n",
    "# print(test)\n",
    "\n",
    "# At this point should have a train and test without Nan values:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHrbzNOMJu7n"
   },
   "source": [
    "---------- End of generic setup code. Actual programming can begin after here ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-10T17:41:12.614111Z",
     "iopub.status.busy": "2022-11-10T17:41:12.610392Z",
     "iopub.status.idle": "2022-11-10T17:41:12.851539Z",
     "shell.execute_reply": "2022-11-10T17:41:12.847221Z",
     "shell.execute_reply.started": "2022-11-10T17:41:12.614060Z"
    },
    "id": "kiinNWOkeH36",
    "outputId": "4ce8249e-ee9c-4dfd-ecba-0d47194e7773",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retained 0.5 of variance with 1 number of features\n",
      "Retained 0.6 of variance with 1 number of features\n",
      "Retained 0.75 of variance with 1 number of features\n",
      "Retained 0.8 of variance with 1 number of features\n",
      "Retained 0.85 of variance with 1 number of features\n",
      "Retained 0.9 of variance with 2 number of features\n",
      "Retained 0.95 of variance with 3 number of features\n",
      "Retained 0.96 of variance with 4 number of features\n",
      "Retained 0.97 of variance with 4 number of features\n",
      "Retained 0.98 of variance with 5 number of features\n",
      "Retained 0.99 of variance with 5 number of features\n"
     ]
    }
   ],
   "source": [
    "# USE the code we wrote above\n",
    "test_, train, labels = replaceNanWithZero(test, train, train_labels)\n",
    "\n",
    "PCA_Performance(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mltartu-kernel",
   "language": "python",
   "name": "mltartu-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
